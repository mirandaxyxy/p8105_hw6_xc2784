p8105_hw6_xc2784
================
2025-12-03

### Problem 1

``` r
raw = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

``` r
homicides <- raw %>%
  mutate(
    city_state = str_c(city, ", ", state),
    solved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age),
    victim_sex  = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")) %>% 
  filter(
    !(city == "Dallas" & state == "TX"),
    !(city == "Phoenix" & state == "AZ"),
    !(city == "Kansas City" & state == "MO"),
    !(city == "Tulsa" & state == "AL"),
    (victim_race %in% c("White", "Black")) 
  ) %>% 
    drop_na(
    solved,
    victim_age,
    victim_sex,
    victim_race
  )
```

``` r
baltimore <- homicides %>%
  filter(city_state == "Baltimore, MD")

baltimore_lr <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore,
  family = binomial
)

baltimore_or <- tidy(baltimore_lr, conf.int = TRUE, exponentiate = TRUE) %>%
 mutate(OR = estimate)%>%
  select(term, OR, conf.low, conf.high)

baltimore_or
```

    ## # A tibble: 4 Ã— 4
    ##   term                OR conf.low conf.high
    ##   <chr>            <dbl>    <dbl>     <dbl>
    ## 1 (Intercept)      3.16     2.00      5.06 
    ## 2 victim_age       0.993    0.987     1.000
    ## 3 victim_sexMale   0.426    0.324     0.558
    ## 4 victim_raceBlack 0.431    0.305     0.606

In Baltimore, male victimsâ€™ homicide cases are 57% less likely to be
resolved than those of female victims (adjusted OR = 0.43; 95% CI:
0.32â€“0.58), controlling for age and race.

``` r
library(purrr)

city_or <- homicides %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    model = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x, family = binomial
    )),
    results = map(model, ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) %>%
  unnest(results) %>%
  filter(term == "victim_sexMale")  %>% 
  mutate(OR = estimate)%>%
  select(city_state, OR, conf.low, conf.high)
  

city_or
```

    ## # A tibble: 47 Ã— 4
    ## # Groups:   city_state [47]
    ##    city_state         OR conf.low conf.high
    ##    <chr>           <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM 1.77     0.825     3.76 
    ##  2 Atlanta, GA     1.00     0.680     1.46 
    ##  3 Baltimore, MD   0.426    0.324     0.558
    ##  4 Baton Rouge, LA 0.381    0.204     0.684
    ##  5 Birmingham, AL  0.870    0.571     1.31 
    ##  6 Boston, MA      0.674    0.353     1.28 
    ##  7 Buffalo, NY     0.521    0.288     0.936
    ##  8 Charlotte, NC   0.884    0.551     1.39 
    ##  9 Chicago, IL     0.410    0.336     0.501
    ## 10 Cincinnati, OH  0.400    0.231     0.667
    ## # â„¹ 37 more rows

``` r
library(ggplot2)

city_ordered <- city_or %>%
  ungroup() %>% 
  arrange(OR) %>% 
  mutate(city_state = factor(city_state,levels = city_state))


city_plot <- ggplot(city_ordered, aes(x = OR, y = city_state)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  geom_vline(xintercept = 1, linetype = "dashed") +
    labs(
      x = "Adjusted OR (Male vs Female Victims)",
      y = "City, State",
      title = "Adjusted Odds Ratios for Resolved Homicides by City"
    ) +
  theme_minimal()

city_plot
```

![](p8105_hw6_xc2784_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Most cities have ORs below 1, suggesting that homicides involving male
victims tend to be solved at lower rates than those involving female
victims once age and race are accounted for. A few cities, such as
Albuquerque, Stockton, and Fresno, show ORs above 1, indicating the
opposite pattern, but these are exceptions. However, most cities have
ORs near 1, and their confidence intervals cross 1, suggesting there is
little evidence of a statistically difference in resolved rates between
male and female victims after adjusting for age and race.

### Problem 2

``` r
library(p8105.datasets)
data("weather_df")

weather <-
  weather_df %>% 
  filter(name == "CentralPark_NY") %>% 
  drop_na(tmax, tmin, prcp)

reg = lm(tmax ~ tmin + prcp, data = weather)
reg %>% glance() %>% select(r.squared)
```

    ## # A tibble: 1 Ã— 1
    ##   r.squared
    ##       <dbl>
    ## 1     0.912

``` r
reg %>% tidy()
```

    ## # A tibble: 3 Ã— 5
    ##   term        estimate std.error statistic   p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept)  7.56     0.162        46.6  1.31e-220
    ## 2 tmin         1.03     0.0119       86.9  0        
    ## 3 prcp        -0.00157  0.000966     -1.63 1.04e-  1

``` r
set.seed(1)
n_boot <- 5000

boot_samples <-
  weather %>%
  modelr::bootstrap(n = n_boot, id = "strap_id")

boot_results <-
  boot_samples %>%
  mutate(
    fit  = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    gl   = map(fit, glance),
    coef = map(fit, tidy)
  ) %>%
  mutate(
    r_sq = map_dbl(gl, "r.squared"),
    beta_ratio = map_dbl(
      coef,
      ~ {
        tmp <- .x %>% select(term, estimate)
        
        b_tmin <- tmp %>%
          filter(term == "tmin") %>%
          pull(estimate)
        
        b_prcp <- tmp %>%
          filter(term == "prcp") %>%
          pull(estimate)
        
        b_tmin / b_prcp
      }
    )
  ) %>%
  select(strap_id, r_sq, beta_ratio)

boot_results
```

    ## # A tibble: 5,000 Ã— 3
    ##    strap_id  r_sq beta_ratio
    ##    <chr>    <dbl>      <dbl>
    ##  1 0001     0.913      -237.
    ##  2 0002     0.921      -424.
    ##  3 0003     0.905     -1492.
    ##  4 0004     0.921      -364.
    ##  5 0005     0.906      -461.
    ##  6 0006     0.915      -634.
    ##  7 0007     0.919      -808.
    ##  8 0008     0.905     -2435.
    ##  9 0009     0.917      -723.
    ## 10 0010     0.916      -344.
    ## # â„¹ 4,990 more rows

``` r
p1 = boot_results %>%
  ggplot(aes(x = r_sq)) +
  geom_histogram() +
  theme_minimal() +
  labs(x = "R-squared", title = "Bootstrap distribution of R-squared")

p2 = boot_results %>%
  ggplot(aes(x = beta_ratio)) +
  geom_histogram() +
  theme_minimal() +
  labs(x = "Î²1 / Î²2",
       title = "Bootstrap distribution of beta ratio")

p1+p2
```

![](p8105_hw6_xc2784_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

``` r
boot_results %>%
  summarize(
    r2_025  = quantile(r_sq, 0.025),
    r2_975  = quantile(r_sq, 0.975),
    br_025  = quantile(beta_ratio, 0.025),
    br_974  = quantile(beta_ratio, 0.975)
  )
```

    ## # A tibble: 1 Ã— 4
    ##   r2_025 r2_975 br_025 br_974
    ##    <dbl>  <dbl>  <dbl>  <dbl>
    ## 1  0.894  0.928 -5616.  4587.

From the bootstrap results: r2: 95% CI: \[0.89, 0.93\] ð›½1/ð›½2: 95% CI:
\[â€“5616.45, 4568.92\]

The bootstrap distribution of r2 is more concentrated and normally
distributed, with most values falling around 0.91â€“0.93. This suggests
that the fitted model gives similar r2 values across bootstrap samples.

The bootstrap distribution of the beta ratio ð›½1/ð›½2 is much more spread
out, with values covering a very wide range and a tall spike near zero.
This indicates that the ratio varies a lot from sample to sample, and
its values can become quite large in magnitude. This happens because the
coefficient for precipitation is close to zero and flips sign across
samples.

### problem 3

``` r
birthweight = 
  read_csv("./birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(
      babysex,
      levels = c(1, 2),
      labels = c("male", "female")
    ),
    frace = factor(
      frace,
      levels = c(1, 2, 3, 4, 8, 9),
      labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")
    ),
    mrace = factor(
      mrace,
      levels = c(1, 2, 3, 4, 8),
      labels = c("White", "Black", "Asian", "Puerto Rican", "Other")
    ),
    malform = factor(
      malform,
      levels = c(0, 1),
      labels = c("absent", "present")
    )
  ) %>% 
  drop_na()
```

``` r
## 1. Proposed model for birthweight ------------------------------------
model1 <-
  lm(
    bwt ~ gaweeks + blength + bhead +
      babysex + mrace +
      ppbmi + wtgain + smoken,
    data = birthweight
  )

summary(model1)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ gaweeks + blength + bhead + babysex + mrace + 
    ##     ppbmi + wtgain + smoken, data = birthweight)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1077.87  -186.66    -3.98   178.85  2393.87 
    ## 
    ## Coefficients:
    ##                     Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       -5745.6445   101.1071 -56.827  < 2e-16 ***
    ## gaweeks              11.2176     1.4672   7.645 2.55e-14 ***
    ## blength              76.4225     2.0195  37.843  < 2e-16 ***
    ## bhead               132.2457     3.4660  38.155  < 2e-16 ***
    ## babysexfemale        31.5927     8.5059   3.714 0.000206 ***
    ## mraceBlack         -147.8576     9.2848 -15.925  < 2e-16 ***
    ## mraceAsian          -96.6499    42.5278  -2.273 0.023097 *  
    ## mracePuerto Rican  -138.4455    18.7592  -7.380 1.89e-13 ***
    ## ppbmi                 7.0808     1.3372   5.295 1.25e-07 ***
    ## wtgain                4.0902     0.3947  10.364  < 2e-16 ***
    ## smoken               -4.6265     0.5887  -7.859 4.85e-15 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 274.3 on 4331 degrees of freedom
    ## Multiple R-squared:  0.7137, Adjusted R-squared:  0.7131 
    ## F-statistic:  1080 on 10 and 4331 DF,  p-value: < 2.2e-16

I selected predictors based on biological factors that are known to
influence birthweight, such as gestational age, birth size measurements,
and maternal characteristics. I also included smoking and demographic
variables because they are commonly associated with differences in
birthweight.

``` r
tidy(model1)
```

    ## # A tibble: 11 Ã— 5
    ##    term              estimate std.error statistic   p.value
    ##    <chr>                <dbl>     <dbl>     <dbl>     <dbl>
    ##  1 (Intercept)       -5746.     101.       -56.8  0        
    ##  2 gaweeks              11.2      1.47       7.65 2.55e- 14
    ##  3 blength              76.4      2.02      37.8  5.28e-271
    ##  4 bhead               132.       3.47      38.2  7.15e-275
    ##  5 babysexfemale        31.6      8.51       3.71 2.06e-  4
    ##  6 mraceBlack         -148.       9.28     -15.9  1.56e- 55
    ##  7 mraceAsian          -96.6     42.5       -2.27 2.31e-  2
    ##  8 mracePuerto Rican  -138.      18.8       -7.38 1.89e- 13
    ##  9 ppbmi                 7.08     1.34       5.30 1.25e-  7
    ## 10 wtgain                4.09     0.395     10.4  7.04e- 25
    ## 11 smoken               -4.63     0.589     -7.86 4.85e- 15

``` r
glance(model1)
```

    ## # A tibble: 1 Ã— 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.714         0.713  274.     1080.       0    10 -30533. 61090. 61166.
    ## # â„¹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

``` r
birthweight_resid <-
  birthweight %>%
  add_predictions(model1) %>%
  add_residuals(model1)

birthweight_resid %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme_minimal() +
  labs(
    x = "Fitted birthweight",
    y = "Residual",
    title = "Residuals vs fitted values for proposed birthweight model"
  )
```

![](p8105_hw6_xc2784_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->
The residuals are mostly centered around zero with no clear pattern,
indicating the model fits reasonably well. There is some increase in
spread at higher fitted birthweights and a few noticeable outliers, but
the overall structure looks acceptable for a linear model.

Compare my model to two others:

``` r
model2 <- lm(bwt ~ blength + gaweeks, data = birthweight)
model3 <- lm(bwt ~ bhead * blength * babysex, data = birthweight)
```

Cross-validated prediction error comparison

``` r
set.seed(1)

cv_df <- 
  crossv_mc(birthweight, n = 100) %>%   
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble)
  )

cv_models <- 
  cv_df %>%
  mutate(
    mod1 = map(train, ~ lm(
      bwt ~ gaweeks + blength + bhead +
        babysex + mrace + ppbmi + wtgain + smoken,
      data = .x
    )),
    mod2 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    mod3 = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x))
  ) %>%
    mutate(
    rmse1 = map2_dbl(mod1, test, ~ rmse(.x, .y)),
    rmse2 = map2_dbl(mod2, test, ~ rmse(.x, .y)),
    rmse3 = map2_dbl(mod3, test, ~ rmse(.x, .y))
  )

cv_long <- 
  cv_models %>%
  select(rmse1, rmse2, rmse3) %>%
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse"
  ) %>%
  mutate(
    model = recode(
      model,
      rmse1 = "Proposed model1",
      rmse2 = "Model2",
      rmse3 = "Model3"
    )
  )

cv_long %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  theme_minimal() +
  labs(
    x = NULL,
    y = "RMSE (grams)",
    title = "Cross-validated prediction error for three birthweight models"
  )
```

![](p8105_hw6_xc2784_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->
The cross-validated RMSE values show clear differences in predictive
performance among the three models. Model 2, which uses only birth
length and gestational age, has noticeably higher RMSE values,
indicating weaker predictive accuracy. Model 3 performs better, with
lower RMSEs, but the proposed Model 1 achieves the lowest errors
overall, suggesting it provides the best predictions among the three.
